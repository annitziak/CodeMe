{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook for time + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "from retrieval_models.data_loaders import Index\n",
    "from retrieval_models.retrieval_functions import *\n",
    "from retrieval_models.reranking import Reranker\n",
    "from retrieval_models.evaluation_metrics import *\n",
    "import tqdm \n",
    "import os\n",
    "import time\n",
    "from scipy.stats import kendalltau, spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'NoneType' object is not subscriptable in Python\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#import all the 25 examples used for ranked retrieval\n",
    "queries_examples = []\n",
    "BASE_DIR = os.getcwd()\n",
    "index_path = os.path.join(BASE_DIR, \"data\", \"queries_examples.txt\")\n",
    "with open(index_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "    queries_examples = [line.strip() for line in file if line.strip()]  # Remove empty lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the object index of the class Index\n",
    "index = Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: [-0.18265761  0.33220416  0.08295575 -0.00454214  0.13252828] of size 768...\n"
     ]
    }
   ],
   "source": [
    "#after precomputing the embeddings load them in\n",
    "def load_and_get_embedding(word, save_path=\"data/embeddings.pkl\"):\n",
    "    \"function that loads the embeddings and returns the embedding of the word\"\n",
    "    with open(save_path, \"rb\") as f:\n",
    "        embeddings, word_to_index = pickle.load(f)\n",
    "    \n",
    "    return embeddings[word_to_index[word]] if word in word_to_index else None\n",
    "\n",
    "# Example usage\n",
    "embedding_vector = load_and_get_embedding(\"java\")\n",
    "if embedding_vector is not None:\n",
    "    print(f\"Embedding: {embedding_vector[:5]} of size {len(embedding_vector)}...\")  # Print first 5 values for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over queries and print results\n",
    "def run_queries(queries_examples, index, embedding_model=None, expansion=False, k=10):\n",
    "    \"\"\"\n",
    "    Runs retrieval for a list of queries and prints top results.\n",
    "    Also prints the total execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timer\n",
    "    retrieved_docs = {}\n",
    "    \n",
    "    for query in tqdm.tqdm(queries_examples):\n",
    "        print(\"Query:\", query)\n",
    "        top_results = retrieval_function(query, index,embedding_model, expansion, k)\n",
    "        print(\"Top results:\", top_results)\n",
    "        print(\"\\n\")\n",
    "        retrieved_docs[query]=top_results\n",
    "\n",
    "    end_time = time.time()  # End timer\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total Execution Time: {total_time:.4f} seconds\")\n",
    "    print(f\"Average Time per Query: {total_time / len(queries_examples):.4f} seconds\")\n",
    "\n",
    "    return total_time, retrieved_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: TypeError: 'NoneType' object is not subscriptable in Python\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:01<00:30,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1490039', '1308079', '631788', '1689012', '1449620', '1689145', '768941', '1115313', '1772491', '550585']\n",
      "\n",
      "\n",
      "Query: NullPointerException handling in Java\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:02<00:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1345786', '1264818', '1733292', '1184789', '1366832', '767009', '1028892', '1607800', '1697522', '961538']\n",
      "\n",
      "\n",
      "Query: ModuleNotFoundError: No module named 'requests'\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:04<00:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['818020', '816834', '1731441', '1477365']\n",
      "\n",
      "\n",
      "Query: Segmentation fault in C++\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:04<00:21,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['818020', '816834', '1731441', '1477365', '1790201', '742549', '1251464', '960382', '1119373', '1649067']\n",
      "\n",
      "\n",
      "Query: SyntaxError: invalid syntax near 'elif'\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:05<00:17,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1452239', '730064', '756384', '937491', '1256311', '971177', '1111227', '829798', '829916', '491999']\n",
      "\n",
      "\n",
      "Query: Difference between DFS and BFS algorithms\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:06<00:09,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1658569', '1432429', '1567015', '694369', '820054', '1054626', '590393', '754448', '844822', '1432093']\n",
      "\n",
      "\n",
      "Query: How does garbage collection work in Java?\n",
      "Starting ranked search\n",
      "Top results: ['829525', '1268725', '823764', '1790201', '1595849', '1452953', '765129', '630056', '1099837', '1251706']\n",
      "\n",
      "\n",
      "Query: What is tail recursion, and how does it optimize memory\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:06<00:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1309138', '846862', '829525', '1218241', '1153609', '715807', '1698916', '810931', '841713', '1595849']\n",
      "\n",
      "\n",
      "Query: What are strong and weak references in Python?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [00:07<00:07,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['740943', '927179', '1088350', '1263783', '585004', '824002', '1410832', '1774106', '1351664', '1611961']\n",
      "\n",
      "\n",
      "Query: Explain dynamic programming with an example\n",
      "Starting ranked search\n",
      "Top results: ['1724137', '1547201', '1547196', '1724304', '1271643', '1516174', '1547210', '1285655', '1529201', '1289174']\n",
      "\n",
      "\n",
      "Query: Best way to concatenate strings in Python\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:07<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['994671', '631788', '533768', '1115313', '1529527', '1728697', '1504378', '749796', '1547019', '1067806']\n",
      "\n",
      "\n",
      "Query: How to optimize SQL queries for large datasets?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [00:08<00:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['829525', '1307149', '1246261', '1771987', '1126083', '1595849', '765129', '630056', '1099837', '1387453']\n",
      "\n",
      "\n",
      "Query: When to use pointers in C++?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [00:09<00:03,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['786163', '1251706', '786235', '585363', '988763', '765054', '1790201', '742549', '1217479', '1251464']\n",
      "\n",
      "\n",
      "Query: Why is binary search faster than linear search?\n",
      "Starting ranked search\n",
      "Top results: ['545003', '721797', '1275665', '1275799', '700241', '1233667', '1602944', '1727208', '750433', '1505510']\n",
      "\n",
      "\n",
      "Query: How to improve performance of nested loops in Java?\n",
      "Starting ranked search\n",
      "Top results: ['1176423', '1350261', '1479089', '730848', '1387726', '745765', '778397', '1133205', '642228', '1404310']\n",
      "\n",
      "\n",
      "Query: How to use Pandas groupby with multiple columns?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:09<00:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['892296', '1113038', '829525', '1234550', '1508979', '1658880', '1595849', '579255', '765129', '630056']\n",
      "\n",
      "\n",
      "Query: What does std::move do in C++?\n",
      "Starting ranked search\n",
      "Top results: ['1519597', '1168200', '1050889', '818020', '1790201', '742549', '1415335', '1436035', '1251464', '1602852']\n",
      "\n",
      "\n",
      "Query: Difference between apply() and map() in Pandas\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:09<00:01,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1567015', '846862', '901098', '703931', '1218241', '1698916', '810931', '1199490', '1790201', '742549']\n",
      "\n",
      "\n",
      "Query: How to use React hooks for state management?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [00:10<00:01,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['829525', '1234550', '1771987', '1595849', '765129', '630056', '1099837', '1532236', '690121', '1113029']\n",
      "\n",
      "\n",
      "Query: How to make an API request with Axios in JavaScript?\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [00:10<00:01,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1547201', '1547196', '1724304', '1724137', '1516174', '1547210', '1285655', '1529201', '1289174', '1289099']\n",
      "\n",
      "\n",
      "Query: I want pasta for dinner\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [00:11<00:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['598370', '691795', '679049', '1017046', '589358', '950412', '1206005', '849900', '1035895', '908521']\n",
      "\n",
      "\n",
      "Query: coding is very hard\n",
      "Starting ranked search\n",
      "Top results: ['967819', '791750', '1059895', '881871', '789811', '767778', '935224', '876985', '828294', '817297']\n",
      "\n",
      "\n",
      "Query: ajdejfn code\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [00:11<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['796224', '1358525', '682310', '508002', '924898', '1358531', '1522476', '912207', '1523515', '1523147']\n",
      "\n",
      "\n",
      "Query: how to make a website\n",
      "Starting ranked search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['747929', '659184', '498152', '829525', '616617', '1151345', '492006', '579255', '1595849', '765129']\n",
      "\n",
      "\n",
      "Total Execution Time: 11.9127 seconds\n",
      "Average Time per Query: 0.4964 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#the basic top k results for each query\n",
    "_,retrieved_docs = run_queries(queries_examples, index, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Query Expansion to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingmodel = EmbeddingModel(vocab = index.vocab, save_path=\"data/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: TypeError: 'NoneType' object is not subscriptable in Python\n",
      "Starting ranked search\n",
      "Word 'typeerror:' not found in precomputed embeddings\n",
      "❌ Word 'typeerror:' not found in vocabulary. Cannot find similar words.\n",
      "Word ''nonetype'' not found in precomputed embeddings\n",
      "❌ Word ''nonetype'' not found in vocabulary. Cannot find similar words.\n",
      "[113939 152264  34870]\n",
      "Word 'is' not found in precomputed embeddings\n",
      "❌ Word 'is' not found in vocabulary. Cannot find similar words.\n",
      "[127957   4118]\n",
      "Word 'subscriptable' not found in precomputed embeddings\n",
      "❌ Word 'subscriptable' not found in vocabulary. Cannot find similar words.\n",
      "[116217]\n",
      "[ 94587 219529 151324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:05<01:57,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1490039', '1308079', '631788', '1689012', '1449620', '598010', '597178', '1689145', '768941', '1115313', '1772491', '550585', '550915', '768956', '1529527', '1689139', '999182', '1728697', '550868', '1223197', '1601656', '506956', '1646326', '1264818', '1385753', '772220', '745600', '1520897', '1593100', '788935']\n",
      "\n",
      "\n",
      "Query: NullPointerException handling in Java\n",
      "Starting ranked search\n",
      "Word 'nullpointerexception' not found in precomputed embeddings\n",
      "❌ Word 'nullpointerexception' not found in vocabulary. Cannot find similar words.\n",
      "Word 'handling' not found in precomputed embeddings\n",
      "❌ Word 'handling' not found in vocabulary. Cannot find similar words.\n",
      "[116217  80748]\n",
      "[134191  97021]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:08<01:26,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1202552', '1345786', '1264818', '1733292', '883621', '1184789', '1366832', '767009', '1028892', '817562', '1607800', '1697522', '961538', '1125604', '1580091', '1593100', '609329', '1259460', '580511', '1202530', '1514112', '1533812', '1202523', '841292', '1711103', '889924', '593397', '688002', '998049', '1208295']\n",
      "\n",
      "\n",
      "Query: ModuleNotFoundError: No module named 'requests'\n",
      "Starting ranked search\n",
      "Word 'modulenotfounderror:' not found in precomputed embeddings\n",
      "❌ Word 'modulenotfounderror:' not found in vocabulary. Cannot find similar words.\n",
      "Word 'no' not found in precomputed embeddings\n",
      "❌ Word 'no' not found in vocabulary. Cannot find similar words.\n",
      "Word 'module' not found in precomputed embeddings\n",
      "❌ Word 'module' not found in vocabulary. Cannot find similar words.\n",
      "Word 'named' not found in precomputed embeddings\n",
      "❌ Word 'named' not found in vocabulary. Cannot find similar words.\n",
      "Word ''requests'' not found in precomputed embeddings\n",
      "❌ Word ''requests'' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:09<00:57,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['818020', '816834', '1731441', '1477365']\n",
      "\n",
      "\n",
      "Query: Segmentation fault in C++\n",
      "Starting ranked search\n",
      "Word 'segmentation' not found in precomputed embeddings\n",
      "❌ Word 'segmentation' not found in vocabulary. Cannot find similar words.\n",
      "[63562]\n",
      "[116217]\n",
      "Word 'c++' not found in precomputed embeddings\n",
      "❌ Word 'c++' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:11<00:50,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['598611', '1070621', '1411119', '1007080', '1277212', '603521', '803472', '980708', '1367027', '1186922', '1467150', '1633993', '953639', '818020', '1441647', '974471', '679302', '1627929', '816834', '1731441', '1477365', '989485', '1130819', '1790201', '742549', '1251464', '1106181', '960382', '1119373', '1649067']\n",
      "\n",
      "\n",
      "Query: SyntaxError: invalid syntax near 'elif'\n",
      "Starting ranked search\n",
      "Word 'syntaxerror:' not found in precomputed embeddings\n",
      "❌ Word 'syntaxerror:' not found in vocabulary. Cannot find similar words.\n",
      "[128994  58589]\n",
      "[ 15769 185524  76992]\n",
      "[44624 26196]\n",
      "Word ''elif'' not found in precomputed embeddings\n",
      "❌ Word ''elif'' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:14<00:50,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1609510', '1452239', '558053', '730064', '1448941', '756384', '937491', '1256311', '971177', '1111227', '829798', '829916', '491999', '1432968', '826948', '1227605', '696889', '584284', '614993', '1776176', '659061', '1396782', '1291502', '1661491', '624492', '1439123', '609675', '1281654', '1529957', '1719624']\n",
      "\n",
      "\n",
      "Query: Difference between DFS and BFS algorithms\n",
      "Starting ranked search\n",
      "Word 'difference' not found in precomputed embeddings\n",
      "❌ Word 'difference' not found in vocabulary. Cannot find similar words.\n",
      "[135717]\n",
      "[47515 52771 47561]\n",
      "[ 6406 37723]\n",
      "[28649]\n",
      "Word 'algorithms' not found in precomputed embeddings\n",
      "❌ Word 'algorithms' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [00:17<00:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1658569', '1432429', '1567015', '694369', '820054', '1054626', '590393', '754448', '844822', '1432093', '862624', '1432024', '1636119', '1383231', '1403484', '827647', '1657167', '1657248', '812505', '829177', '1434787', '1150723', '1083028', '1484876', '685861', '829156', '1441880', '1657174', '998520', '1372993']\n",
      "\n",
      "\n",
      "Query: How does garbage collection work in Java?\n",
      "Starting ranked search\n",
      "[ 59294 209620]\n",
      "Word 'does' not found in precomputed embeddings\n",
      "❌ Word 'does' not found in vocabulary. Cannot find similar words.\n",
      "Word 'garbage' not found in precomputed embeddings\n",
      "❌ Word 'garbage' not found in vocabulary. Cannot find similar words.\n",
      "Word 'collection' not found in precomputed embeddings\n",
      "❌ Word 'collection' not found in vocabulary. Cannot find similar words.\n",
      "[209056 212306 186841]\n",
      "[116217]\n",
      "Word 'java?' not found in precomputed embeddings\n",
      "❌ Word 'java?' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:20<00:46,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1309138', '668171', '829525', '1268725', '823764', '1790201', '569315', '1661771', '670686', '1595849', '1452953', '701784', '765129', '920845', '630056', '1168200', '1099837', '1251706', '1050889', '818020', '793320', '742549', '1165758', '896840', '639245', '827121', '579255', '1307149', '1436035', '1251464']\n",
      "\n",
      "\n",
      "Query: What is tail recursion, and how does it optimize memory\n",
      "Starting ranked search\n",
      "[190758  83441]\n",
      "Word 'is' not found in precomputed embeddings\n",
      "❌ Word 'is' not found in vocabulary. Cannot find similar words.\n",
      "[ 32757 103142]\n",
      "Word 'recursion,' not found in precomputed embeddings\n",
      "❌ Word 'recursion,' not found in vocabulary. Cannot find similar words.\n",
      "[  6406  37723 108296]\n",
      "[59294]\n",
      "Word 'does' not found in precomputed embeddings\n",
      "❌ Word 'does' not found in vocabulary. Cannot find similar words.\n",
      "[93702  1993]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:25<00:56,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['812505', '829177', '829315', '829156', '1309138', '846862', '1764979', '890461', '1664661', '1272995', '829525', '1096505', '748217', '824562', '1218241', '1153609', '861519', '1186896', '1647755', '715807', '1698916', '1361512', '810931', '841713', '1595849', '765129', '630056', '1082594', '887969', '1704914']\n",
      "\n",
      "\n",
      "Query: What are strong and weak references in Python?\n",
      "Starting ranked search\n",
      "[190758  83441 182007]\n",
      "[164694 210604]\n",
      "[39787]\n",
      "[  6406  37723 108296]\n",
      "[161976 174114 169730]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [00:29<00:56,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['984543', '1596206', '812505', '829177', '740943', '927179', '1088350', '1752808', '1263783', '585004', '829156', '824002', '1410832', '1774106', '1351664', '1611961', '647113', '1547004', '1546960', '1309138', '859200', '797606', '1263655', '1658320', '632159', '1786635', '846862', '1587348', '1072548', '597664']\n",
      "\n",
      "\n",
      "Query: Explain dynamic programming with an example\n",
      "Starting ranked search\n",
      "[45782 34711]\n",
      "[194857]\n",
      "Word 'programming' not found in precomputed embeddings\n",
      "❌ Word 'programming' not found in vocabulary. Cannot find similar words.\n",
      "[179648]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [00:32<00:48,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97084]\n",
      "Word 'example' not found in precomputed embeddings\n",
      "❌ Word 'example' not found in vocabulary. Cannot find similar words.\n",
      "Top results: ['1693835', '885903', '1724137', '1547201', '1547196', '1724304', '1621971', '1271643', '1315570', '1516174', '1547210', '1285655', '589855', '1529201', '1289174', '1091524', '1289099', '1547224', '562770', '1289135', '1736340', '1737786', '558181', '772929', '1288985', '1737763', '1288904', '1697816', '1192007', '1386283']\n",
      "\n",
      "\n",
      "Query: Best way to concatenate strings in Python\n",
      "Starting ranked search\n",
      "[212375  22019  44618]\n",
      "[ 67864 161444 211931]\n",
      "[2 3]\n",
      "Word 'concatenate' not found in precomputed embeddings\n",
      "❌ Word 'concatenate' not found in vocabulary. Cannot find similar words.\n",
      "Word 'strings' not found in precomputed embeddings\n",
      "❌ Word 'strings' not found in vocabulary. Cannot find similar words.\n",
      "[116217  80748  55928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:36<00:45,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1101301', '1540749', '838239', '1574530', '1192881', '1574546', '994671', '1252060', '1076577', '1494087', '1327731', '1641991', '631788', '1089550', '1451407', '614724', '533768', '1115313', '931747', '1538308', '531327', '1135575', '1529527', '1728697', '1504378', '749796', '1547019', '1067806', '1646326', '1264818']\n",
      "\n",
      "\n",
      "Query: How to optimize SQL queries for large datasets?\n",
      "Starting ranked search\n",
      "[59294]\n",
      "[2 3]\n",
      "Word 'optimize' not found in precomputed embeddings\n",
      "❌ Word 'optimize' not found in vocabulary. Cannot find similar words.\n",
      "[152137 119619]\n",
      "Word 'queries' not found in precomputed embeddings\n",
      "❌ Word 'queries' not found in vocabulary. Cannot find similar words.\n",
      "[220722 211265  70490]\n",
      "Word 'large' not found in precomputed embeddings\n",
      "❌ Word 'large' not found in vocabulary. Cannot find similar words.\n",
      "Word 'datasets?' not found in precomputed embeddings\n",
      "❌ Word 'datasets?' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [00:39<00:42,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['838239', '829525', '1668702', '1252060', '1318667', '1607548', '1494087', '1420382', '1446421', '1436359', '1135653', '618406', '1659686', '552777', '1223398', '1166032', '935121', '1117887', '1538308', '1136273', '869164', '1617835', '1254838', '1460064', '1618198', '1729147', '841783', '678420', '471305', '1367344']\n",
      "\n",
      "\n",
      "Query: When to use pointers in C++?\n",
      "Starting ranked search\n",
      "[209811  86286  71833]\n",
      "[ 2  3 99]\n",
      "[202713]\n",
      "Word 'pointers' not found in precomputed embeddings\n",
      "❌ Word 'pointers' not found in vocabulary. Cannot find similar words.\n",
      "[116217  80748]\n",
      "Word 'c++?' not found in precomputed embeddings\n",
      "❌ Word 'c++?' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [00:42<00:37,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['838239', '1252060', '1494087', '1538308', '948068', '1166032', '607319', '1328843', '1497468', '1089563', '842833', '1674109', '1527146', '1129040', '745837', '1621957', '598121', '900766', '1090462', '1668702', '1202530', '1089550', '1338171', '1202523', '1318667', '1390502', '1506655', '1540749', '870477', '1574530']\n",
      "\n",
      "\n",
      "Query: Why is binary search faster than linear search?\n",
      "Starting ranked search\n",
      "Word 'why' not found in precomputed embeddings\n",
      "❌ Word 'why' not found in vocabulary. Cannot find similar words.\n",
      "Word 'is' not found in precomputed embeddings\n",
      "❌ Word 'is' not found in vocabulary. Cannot find similar words.\n",
      "Word 'binary' not found in precomputed embeddings\n",
      "❌ Word 'binary' not found in vocabulary. Cannot find similar words.\n",
      "[182804]\n",
      "[63505 54571]\n",
      "[189884 189885 189850]\n",
      "[169730  31196 204715]\n",
      "Word 'search?' not found in precomputed embeddings\n",
      "❌ Word 'search?' not found in vocabulary. Cannot find similar words.\n",
      "Top results: ['545003', '721797', '1275665', '1285910', '1275799', '1080495', '700241', '1233667', '1717250', '936907', '1284314', '1602944', '1727208', '750433', '1505510', '1727364', '750416', '1632209', '904641', '554314', '700263', '559777', '1059522', '1374117', '1524227', '796517', '1550970', '1332934', '1744188', '868000']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [00:45<00:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How to improve performance of nested loops in Java?\n",
      "Starting ranked search\n",
      "[ 59294 209620]\n",
      "[ 2  3 99]\n",
      "Word 'improve' not found in precomputed embeddings\n",
      "❌ Word 'improve' not found in vocabulary. Cannot find similar words.\n",
      "Word 'performance' not found in precomputed embeddings\n",
      "❌ Word 'performance' not found in vocabulary. Cannot find similar words.\n",
      "[98390 24783]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [00:48<00:28,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67706 49836 62789]\n",
      "Top results: ['838239', '1252060', '1494087', '1538308', '1648250', '1176423', '1350261', '1479089', '730848', '607319', '1387726', '1328843', '745765', '778397', '1497468', '1309138', '1133205', '642228', '1404310', '1378428', '708595', '1089563', '1621957', '829525', '1310776', '1090462', '1626013', '1668702', '1148880', '1310983']\n",
      "\n",
      "\n",
      "Query: How to use Pandas groupby with multiple columns?\n",
      "Starting ranked search\n",
      "[ 59294 209620]\n",
      "[2]\n",
      "[202713 202634 188656]\n",
      "Word 'pandas' not found in precomputed embeddings\n",
      "❌ Word 'pandas' not found in vocabulary. Cannot find similar words.\n",
      "Word 'groupby' not found in precomputed embeddings\n",
      "❌ Word 'groupby' not found in vocabulary. Cannot find similar words.\n",
      "[179648 108470 201077]\n",
      "Word 'multiple' not found in precomputed embeddings\n",
      "❌ Word 'multiple' not found in vocabulary. Cannot find similar words.\n",
      "Word 'columns?' not found in precomputed embeddings\n",
      "❌ Word 'columns?' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [00:54<00:30,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1044415', '1761015', '1354211', '1720083', '772929', '1437177', '1744062', '1512288', '1309138', '1019653', '1395798', '892296', '1315570', '1163411', '507014', '1113038', '1163442', '829525', '1494087', '558181', '1520010', '1626013', '1191031', '1619657', '1144050', '1318667', '1618674', '734616', '931747', '1234550']\n",
      "\n",
      "\n",
      "Query: What does std::move do in C++?\n",
      "Starting ranked search\n",
      "[190758  83441]\n",
      "Word 'does' not found in precomputed embeddings\n",
      "❌ Word 'does' not found in vocabulary. Cannot find similar words.\n",
      "Word 'std::move' not found in precomputed embeddings\n",
      "❌ Word 'std::move' not found in vocabulary. Cannot find similar words.\n",
      "[110950  51345]\n",
      "[116217  80748  55928]\n",
      "Word 'c++?' not found in precomputed embeddings\n",
      "❌ Word 'c++?' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:56<00:24,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1309138', '1101301', '930813', '829525', '1202530', '1202523', '1519597', '1426701', '1099864', '772037', '1649067', '1170221', '1595849', '765129', '630056', '1168200', '1099837', '1202564', '1050889', '1194533', '619961', '1769480', '818020', '1654788', '668171', '1124670', '1790201', '579255', '1202509', '742549']\n",
      "\n",
      "\n",
      "Query: Difference between apply() and map() in Pandas\n",
      "Starting ranked search\n",
      "Word 'difference' not found in precomputed embeddings\n",
      "❌ Word 'difference' not found in vocabulary. Cannot find similar words.\n",
      "[135717]\n",
      "Word 'apply()' not found in precomputed embeddings\n",
      "❌ Word 'apply()' not found in vocabulary. Cannot find similar words.\n",
      "[  6406  37723 108296]\n",
      "Word 'map()' not found in precomputed embeddings\n",
      "❌ Word 'map()' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:59<00:18,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116217  80748  55928]\n",
      "Word 'pandas' not found in precomputed embeddings\n",
      "❌ Word 'pandas' not found in vocabulary. Cannot find similar words.\n",
      "Top results: ['812505', '829177', '829156', '1567015', '1101301', '846862', '829315', '901098', '968438', '1202530', '703931', '1202523', '1218241', '1099864', '1698916', '772037', '1361512', '810931', '1202564', '1199490', '1790201', '742549', '957376', '1148238', '1251464', '960382', '1119373', '1649067', '993666', '1406660']\n",
      "\n",
      "\n",
      "Query: How to use React hooks for state management?\n",
      "Starting ranked search\n",
      "[ 59294 209620]\n",
      "[2 3]\n",
      "[202713 202634 188656]\n",
      "[154606]\n",
      "Word 'hooks' not found in precomputed embeddings\n",
      "❌ Word 'hooks' not found in vocabulary. Cannot find similar words.\n",
      "[220722 211265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [01:03<00:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['838239', '1494087', '1252060', '1497468', '1655916', '1655979', '1538308', '607319', '1166032', '1328843', '1437177', '1309138', '1167942', '1089563', '470780', '507014', '1621957', '1113038', '829525', '826826', '1090462', '1520010', '1626013', '1668702', '1089550', '1633355', '1711226', '955458', '1318667', '1618674']\n",
      "\n",
      "\n",
      "Query: How to make an API request with Axios in JavaScript?\n",
      "Starting ranked search\n",
      "[ 59294 209620]\n",
      "[2 3]\n",
      "[38603]\n",
      "[97084   687]\n",
      "[ 3090 52766]\n",
      "[31040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [01:08<00:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['838239', '1252060', '1494087', '1488340', '1234550', '1538308', '1693835', '1540749', '996130', '1626013', '607319', '1328843', '1091619', '1039424', '1497468', '1547201', '1309138', '1547196', '869164', '1724304', '1724137', '1621971', '1516174', '1547210', '1089563', '1285655', '1529201', '1391102', '1289174', '1289099']\n",
      "\n",
      "\n",
      "Query: I want pasta for dinner\n",
      "Starting ranked search\n",
      "[ 22003  80499 188635]\n",
      "[100147  54288  57960]\n",
      "[  4436 144915 134944]\n",
      "[220722]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [01:11<00:11,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1247634', '1247818', '739461', '598370', '691795', '950412', '849900', '679049', '1017046', '589358', '1206005', '1301357', '1035895', '908521', '1662827', '1771806', '1476290', '1084009', '858735', '859119', '1104106', '761029', '939890', '1103573', '1742904', '936584', '849928', '889507', '1275781', '1105382']\n",
      "\n",
      "\n",
      "Query: coding is very hard\n",
      "Starting ranked search\n",
      "Word 'coding' not found in precomputed embeddings\n",
      "❌ Word 'coding' not found in vocabulary. Cannot find similar words.\n",
      "Word 'is' not found in precomputed embeddings\n",
      "❌ Word 'is' not found in vocabulary. Cannot find similar words.\n",
      "Word 'very' not found in precomputed embeddings\n",
      "❌ Word 'very' not found in vocabulary. Cannot find similar words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [01:12<00:05,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31966]\n",
      "Top results: ['530494', '967819', '791750', '1059895', '881871', '789811', '767778', '935224', '876985', '828294', '817297', '1499116', '1672478', '739283', '1531795', '695347', '844088', '1688740', '588990', '828207', '1137178', '648708', '583890', '1353881', '1616959', '552026', '758510', '1164685', '660437', '828217']\n",
      "\n",
      "\n",
      "Query: ajdejfn code\n",
      "Starting ranked search\n",
      "Word 'ajdejfn' not found in precomputed embeddings\n",
      "❌ Word 'ajdejfn' not found in vocabulary. Cannot find similar words.\n",
      "[33112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [01:13<00:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1246102', '796224', '1358525', '682310', '508002', '924898', '1358531', '1522476', '912207', '1523515', '1523147', '706964', '1358530', '589554', '1563068', '1355015', '1405985', '1210539', '1358527', '1637385', '1013063', '1075626', '588949', '670204', '1264618', '1736424', '924334', '1674535', '1320736', '946558']\n",
      "\n",
      "\n",
      "Query: how to make a website\n",
      "Starting ranked search\n",
      "[ 59294 209620 134642]\n",
      "[ 2  3 99]\n",
      "[38603 85770 70486]\n",
      "[121157  62659]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:17<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['838239', '1252060', '1376055', '1494087', '607319', '747929', '1538308', '659184', '1376140', '531327', '548548', '599366', '1328843', '557428', '498152', '1497468', '1309138', '869164', '646748', '611109', '1089563', '487289', '580983', '590073', '568490', '1621957', '829525', '616617', '547080', '1090462']\n",
      "\n",
      "\n",
      "Total Execution Time: 77.3966 seconds\n",
      "Average Time per Query: 3.2249 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_,retrieved_docs_emb = run_queries(queries_examples, index, embeddingmodel, expansion=True, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze if the results between the retrieved documents with and without expansion are similar\n",
    "# we will use the jaccard similarity to compare the results\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "for query in queries_examples:\n",
    "    print(f\"Query: {query}\", jaccard_similarity(retrieved_docs[query], retrieved_docs_emb[query]))\n",
    "\n",
    "#this shows that the results are different for the queries with and without expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for the retrieved documents\n",
    "First using the clarity score and then with Jaccobian/cosine similarity of the documents <br>\n",
    "**Clarity scores are all positive** :  A higher Clarity Score means the query retrieves more distinct and focused documents, while a lower score suggests the retrieved documents are more generic or similar to the background corpus <br>\n",
    "**Jaccobian/cosine similarity** : Measures the similarity between the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def load_document_terms(file_path, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Reads document terms from `document_terms.txt` and extracts terms for retrieved documents.\n",
    "    Returns : Counter: A term frequency counter for retrieved documents.\n",
    "    \"\"\"\n",
    "    retrieved_vocab = Counter()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\":\")\n",
    "            if len(parts) < 2:\n",
    "                continue  # Skip malformed lines\n",
    "            \n",
    "            doc_id = parts[0].strip()\n",
    "            if doc_id in retrieved_docs:  # Process only retrieved documents\n",
    "                terms = parts[1].split()\n",
    "                retrieved_vocab.update(terms)  # Count term frequencies\n",
    "\n",
    "    return retrieved_vocab\n",
    "\n",
    "\n",
    "def compute_clarity_score(document_terms_file, retrieved_docs, index):\n",
    "    \"\"\"\n",
    "    Computes the Clarity Score using KL divergence efficiently with `document_terms.txt`.\n",
    "\n",
    "    Args:\n",
    "        document_terms_file (str): Path to the `document_terms.txt` file.\n",
    "        retrieved_docs (list): List of retrieved document IDs.\n",
    "        index (dict): The inverted index with term document frequency (df).\n",
    "\n",
    "    Returns:\n",
    "        float: Clarity Score (higher means query is more specific).\n",
    "    \"\"\"\n",
    "\n",
    "    # extract terms for retrieved documents -> this is way more efficient that going through index file\n",
    "    retrieved_vocab = load_document_terms(document_terms_file, set(retrieved_docs))\n",
    "\n",
    "    # compute probability distribution for retrieved terms\n",
    "    total_retrieved_terms = sum(retrieved_vocab.values())\n",
    "    if total_retrieved_terms == 0:\n",
    "        return 0  \n",
    "\n",
    "    retrieved_probs = {term: count / total_retrieved_terms for term, count in retrieved_vocab.items()}\n",
    "\n",
    "    # Compute Clarity Score using document frequency (df) from index\n",
    "    total_docs = sum(term_data[\"df\"] for term_data in index.values())  # Total number of docs in index\n",
    "    clarity_score = 0.0\n",
    "\n",
    "    for term, p_retrieved in retrieved_probs.items():\n",
    "        p_corpus = index.get(term, {}).get(\"df\", 1e-12) / total_docs  # Use DF as corpus probability\n",
    "        clarity_score += p_retrieved * math.log(p_retrieved / p_corpus)\n",
    "\n",
    "    return clarity_score\n",
    "\n",
    "# Compute Clarity Scores : they all seem positive and good \n",
    "\n",
    "documents_list = retrieved_docs\n",
    "\n",
    "for query in queries_examples:\n",
    "    clarity_score = compute_clarity_score(\"data/document_terms.txt\", documents_list[query], index.get_index())\n",
    "    print(f\"Clarity Score for '{query}': {clarity_score:.4f}\")\n",
    "\n",
    "\n",
    "#higher clarity scores - makes sense as the expansion should make the query more specific\n",
    "\n",
    "#need to visualize the tradeoff with the number of added words!\n",
    "documents_list = retrieved_docs_emb\n",
    "\n",
    "print(\"Results with expansion:\")\n",
    "for query in queries_examples:\n",
    "    clarity_score = compute_clarity_score(\"data/document_terms.txt\", documents_list[query], index.get_index())\n",
    "    print(f\"Clarity Score for '{query}': {clarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_document_terms(file_path, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Reads `document_terms.txt` and extracts terms for retrieved documents.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the document terms file.\n",
    "        retrieved_docs (set): A set of retrieved document IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are doc IDs and values are term lists.\n",
    "    \"\"\"\n",
    "    doc_terms = {}\n",
    "    doc_lengths = {}  # Store document lengths for normalization\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\":\")\n",
    "            if len(parts) < 2:\n",
    "                continue  # Skip malformed lines\n",
    "            \n",
    "            doc_id = parts[0].strip()\n",
    "            if doc_id in retrieved_docs:  # Process only retrieved documents\n",
    "                terms = parts[1].split()\n",
    "                doc_terms[doc_id] = terms\n",
    "                doc_lengths[doc_id] = len(terms)  # Store document length\n",
    "\n",
    "    return doc_terms, doc_lengths\n",
    "\n",
    "\n",
    "def jaccard_similarity(doc1_terms, doc2_terms):\n",
    "    \"\"\"\n",
    "    Computes Jaccard Similarity with length normalization.\n",
    "    J(A, B) = |A ∩ B| / |A ∪ B|\n",
    "    \"\"\"\n",
    "    intersection = len(set(doc1_terms) & set(doc2_terms))\n",
    "    union = len(set(doc1_terms) | set(doc2_terms))\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_document_similarities(document_terms_file, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Computes pairwise Jaccard & Cosine Similarity between retrieved documents with length normalization.\n",
    "\n",
    "    Args:\n",
    "        document_terms_file (str): Path to `document_terms.txt`.\n",
    "        retrieved_docs (list): List of retrieved document IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Average Jaccard & Cosine similarity.\n",
    "    \"\"\"\n",
    "\n",
    "    # load documents and lengths -> we want to normalize!\n",
    "    doc_terms, doc_lengths = load_document_terms(document_terms_file, set(retrieved_docs))\n",
    "    doc_ids = list(doc_terms.keys())\n",
    "\n",
    "    # compute Jaccard Similarity and take the mean\n",
    "    jaccard_scores = []\n",
    "    for doc1, doc2 in itertools.combinations(doc_ids, 2):\n",
    "        jaccard_scores.append(jaccard_similarity(doc_terms[doc1], doc_terms[doc2]))\n",
    "\n",
    "    avg_jaccard = np.mean(jaccard_scores) if jaccard_scores else 0.0\n",
    "\n",
    "    #  compute Cosine Similarity \n",
    "    all_terms = sorted(set(term for terms in doc_terms.values() for term in terms))  # Unique terms\n",
    "    term_index = {term: i for i, term in enumerate(all_terms)}\n",
    "\n",
    "    doc_vectors = []\n",
    "    avg_doc_length = np.mean(list(doc_lengths.values())) if doc_lengths else 1\n",
    "\n",
    "    for doc_id in doc_ids:\n",
    "        term_freq = Counter(doc_terms[doc_id])  # Count term occurrences\n",
    "        vector = np.zeros(len(all_terms))\n",
    "        for term, freq in term_freq.items():\n",
    "            # Apply BM25-style document length normalization\n",
    "            normalized_tf = freq / (freq + 1.5 * (1 - 0.75 + 0.75 * (doc_lengths[doc_id] / avg_doc_length)))\n",
    "            vector[term_index[term]] = normalized_tf\n",
    "        doc_vectors.append(vector)\n",
    "\n",
    "    doc_vectors = np.array(doc_vectors)\n",
    "    cosine_sim_matrix = cosine_similarity(doc_vectors)\n",
    "\n",
    "    # Compute average pairwise cosine similarity\n",
    "    cosine_scores = []\n",
    "    for i in range(len(doc_ids)):\n",
    "        for j in range(i + 1, len(doc_ids)):\n",
    "            cosine_scores.append(cosine_sim_matrix[i, j])\n",
    "\n",
    "    avg_cosine = np.mean(cosine_scores) if cosine_scores else 0.0\n",
    "\n",
    "    return {\n",
    "        \"Average Jaccard Similarity\": avg_jaccard,\n",
    "        \"Average Cosine Similarity\": avg_cosine\n",
    "    }\n",
    "\n",
    "for query in queries_examples:\n",
    "    if retrieved_docs[query]:\n",
    "        similarities = compute_document_similarities(\"data/document_terms.txt\", retrieved_docs[query])\n",
    "        print(f\"Similarities for '{query}': {similarities}\")\n",
    "    else:\n",
    "        print(f\"No retrieved documents for '{query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranked based on metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial list\n",
      "['1490039', '1308079', '631788', '1689012', '1449620', '1689145', '768941', '1115313', '1772491', '550585']\n",
      "after reranking\n",
      "['1115313', '631788', '1490039', '550585', '768941', '1689145', '1308079', '1449620', '1689012', '1772491']\n",
      "initial list\n",
      "['1345786', '1264818', '1733292', '1184789', '1366832', '767009', '1028892', '1607800', '1697522', '961538']\n",
      "after reranking\n",
      "['767009', '961538', '1264818', '1345786', '1607800', '1733292', '1028892', '1184789', '1697522', '1366832']\n",
      "initial list\n",
      "['818020', '816834', '1731441', '1477365']\n",
      "after reranking\n",
      "['816834', '818020', '1477365', '1731441']\n",
      "initial list\n",
      "['818020', '816834', '1731441', '1477365', '1790201', '742549', '1251464', '960382', '1119373', '1649067']\n",
      "after reranking\n",
      "['960382', '816834', '742549', '818020', '1649067', '1119373', '1251464', '1790201', '1477365', '1731441']\n",
      "initial list\n",
      "['1452239', '730064', '756384', '937491', '1256311', '971177', '1111227', '829798', '829916', '491999']\n",
      "after reranking\n",
      "['937491', '971177', '1111227', '491999', '829798', '730064', '756384', '829916', '1256311', '1452239']\n",
      "initial list\n",
      "['1658569', '1432429', '1567015', '694369', '820054', '1054626', '590393', '754448', '844822', '1432093']\n",
      "after reranking\n",
      "['694369', '754448', '590393', '820054', '844822', '1054626', '1432429', '1432093', '1658569', '1567015']\n",
      "initial list\n",
      "['829525', '1268725', '823764', '1790201', '1595849', '1452953', '765129', '630056', '1099837', '1251706']\n",
      "after reranking\n",
      "['765129', '1099837', '630056', '1790201', '1452953', '829525', '823764', '1268725', '1251706', '1595849']\n",
      "initial list\n",
      "['1309138', '846862', '829525', '1218241', '1153609', '715807', '1698916', '810931', '841713', '1595849']\n",
      "after reranking\n",
      "['1153609', '715807', '1309138', '841713', '810931', '846862', '829525', '1218241', '1595849', '1698916']\n",
      "initial list\n",
      "['740943', '927179', '1088350', '1263783', '585004', '824002', '1410832', '1774106', '1351664', '1611961']\n",
      "after reranking\n",
      "['1410832', '585004', '740943', '1774106', '824002', '927179', '1088350', '1351664', '1263783', '1611961']\n",
      "initial list\n",
      "['1724137', '1547201', '1547196', '1724304', '1271643', '1516174', '1547210', '1285655', '1529201', '1289174']\n",
      "after reranking\n",
      "['1271643', '1547210', '1547196', '1285655', '1289174', '1529201', '1516174', '1547201', '1724304', '1724137']\n",
      "initial list\n",
      "['994671', '631788', '533768', '1115313', '1529527', '1728697', '1504378', '749796', '1547019', '1067806']\n",
      "after reranking\n",
      "['749796', '533768', '1115313', '631788', '994671', '1067806', '1504378', '1547019', '1529527', '1728697']\n",
      "initial list\n",
      "['829525', '1307149', '1246261', '1771987', '1126083', '1595849', '765129', '630056', '1099837', '1387453']\n",
      "after reranking\n",
      "['765129', '1307149', '1099837', '630056', '1771987', '829525', '1246261', '1595849', '1126083', '1387453']\n",
      "initial list\n",
      "['786163', '1251706', '786235', '585363', '988763', '765054', '1790201', '742549', '1217479', '1251464']\n",
      "after reranking\n",
      "['765054', '786235', '742549', '786163', '585363', '1790201', '988763', '1217479', '1251706', '1251464']\n",
      "initial list\n",
      "['545003', '721797', '1275665', '1275799', '700241', '1233667', '1602944', '1727208', '750433', '1505510']\n",
      "after reranking\n",
      "['1602944', '700241', '545003', '721797', '750433', '1275665', '1275799', '1233667', '1505510', '1727208']\n",
      "initial list\n",
      "['1176423', '1350261', '1479089', '730848', '1387726', '745765', '778397', '1133205', '642228', '1404310']\n",
      "after reranking\n",
      "['730848', '1176423', '1387726', '778397', '642228', '745765', '1350261', '1133205', '1479089', '1404310']\n",
      "initial list\n",
      "['892296', '1113038', '829525', '1234550', '1508979', '1658880', '1595849', '579255', '765129', '630056']\n",
      "after reranking\n",
      "['765129', '579255', '1113038', '630056', '1234550', '829525', '892296', '1595849', '1508979', '1658880']\n",
      "initial list\n",
      "['1519597', '1168200', '1050889', '818020', '1790201', '742549', '1415335', '1436035', '1251464', '1602852']\n",
      "after reranking\n",
      "['742549', '1415335', '818020', '1050889', '1790201', '1168200', '1251464', '1519597', '1602852', '1436035']\n",
      "initial list\n",
      "['1567015', '846862', '901098', '703931', '1218241', '1698916', '810931', '1199490', '1790201', '742549']\n",
      "after reranking\n",
      "['1199490', '742549', '703931', '1790201', '901098', '810931', '1218241', '846862', '1567015', '1698916']\n",
      "initial list\n",
      "['829525', '1234550', '1771987', '1595849', '765129', '630056', '1099837', '1532236', '690121', '1113029']\n",
      "after reranking\n",
      "['765129', '690121', '1113029', '630056', '1099837', '829525', '1234550', '1595849', '1771987', '1532236']\n",
      "initial list\n",
      "['1547201', '1547196', '1724304', '1724137', '1516174', '1547210', '1285655', '1529201', '1289174', '1289099']\n",
      "after reranking\n",
      "['1547210', '1289099', '1547196', '1285655', '1289174', '1529201', '1516174', '1547201', '1724304', '1724137']\n",
      "initial list\n",
      "['598370', '691795', '679049', '1017046', '589358', '950412', '1206005', '849900', '1035895', '908521']\n",
      "after reranking\n",
      "['908521', '679049', '1017046', '691795', '849900', '589358', '598370', '950412', '1035895', '1206005']\n",
      "initial list\n",
      "['967819', '791750', '1059895', '881871', '789811', '767778', '935224', '876985', '828294', '817297']\n",
      "after reranking\n",
      "['789811', '817297', '881871', '767778', '791750', '828294', '935224', '1059895', '967819', '876985']\n",
      "initial list\n",
      "['796224', '1358525', '682310', '508002', '924898', '1358531', '1522476', '912207', '1523515', '1523147']\n",
      "after reranking\n",
      "['682310', '508002', '1523515', '796224', '912207', '1358525', '924898', '1523147', '1358531', '1522476']\n",
      "initial list\n",
      "['747929', '659184', '498152', '829525', '616617', '1151345', '492006', '579255', '1595849', '765129']\n",
      "after reranking\n",
      "['659184', '765129', '492006', '1151345', '616617', '498152', '579255', '747929', '829525', '1595849']\n"
     ]
    }
   ],
   "source": [
    "#the reranker ranks mostly every time differently than the initial retrieval\n",
    "\n",
    "reranked = Reranker()\n",
    "#print(reranked.metadata)\n",
    "reranked.metadata[\"id\"] = reranked.metadata[\"id\"].astype(str).str.strip()\n",
    "reranked_doc_list={}\n",
    "for key,retrieved_docs_list in retrieved_docs.items():\n",
    "    print(\"Initial list: \")\n",
    "    print(retrieved_docs_list)\n",
    "    if retrieved_docs_list!=\"No relevant documents found for this query.\":\n",
    "        print(\"After reranking:\")\n",
    "        reranked_doc_list[key]=reranked.rerank_metadata(retrieved_docs_list)\n",
    "        print(reranked_doc_list[key])\n",
    "    else:\n",
    "        print(\"No reranking:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranked based on LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 1000000\n"
     ]
    }
   ],
   "source": [
    "file_path_1 = os.path.join(parent_dir, \"retrieval_models\", \"data\", \"half_1.pkl\")\n",
    "with open(file_path_1, \"rb\") as f:\n",
    "    data_1 = pickle.load(f)  # Load first dictionary\n",
    "\n",
    "file_path_2 = os.path.join(parent_dir, \"retrieval_models\", \"data\", \"half_2.pkl\")\n",
    "with open(file_path_2, \"rb\") as f:\n",
    "    data_2 = pickle.load(f)  # Load second dictionary\n",
    "\n",
    "# Ensure both are dictionaries before merging\n",
    "if isinstance(data_1, dict) and isinstance(data_2, dict):\n",
    "    lm_documents = {**data_1, **data_2}  # Merge both dictionaries (overwrites duplicates)\n",
    "else:\n",
    "    lm_documents = {}  # Empty dictionary if loading failed\n",
    "\n",
    "# Print number of documents\n",
    "print(f\"Total documents loaded: {len(lm_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before reranking\n",
      "['1490039', '1308079', '631788', '1689012', '1449620', '1689145', '768941', '1115313', '1772491', '550585']\n",
      "after reranking\n",
      "['1308079', '631788', '1490039', '1689012', '1449620', '550585', '768941', '1689145', '1115313', '1772491']\n",
      "before reranking\n",
      "['1345786', '1264818', '1733292', '1184789', '1366832', '767009', '1028892', '1607800', '1697522', '961538']\n",
      "after reranking\n",
      "['1264818', '1366832', '1607800', '1733292', '767009', '961538', '1697522', '1184789', '1345786', '1028892']\n",
      "before reranking\n",
      "['818020', '816834', '1731441', '1477365']\n",
      "after reranking\n",
      "['816834', '1477365', '1731441', '818020']\n",
      "before reranking\n",
      "['818020', '816834', '1731441', '1477365', '1790201', '742549', '1251464', '960382', '1119373', '1649067']\n",
      "after reranking\n",
      "['1119373', '1731441', '816834', '742549', '1477365', '1251464', '1649067', '1790201', '818020', '960382']\n",
      "before reranking\n",
      "['1452239', '730064', '756384', '937491', '1256311', '971177', '1111227', '829798', '829916', '491999']\n",
      "after reranking\n",
      "['829798', '937491', '1452239', '730064', '971177', '756384', '829916', '1111227', '1256311', '491999']\n",
      "before reranking\n",
      "['1658569', '1432429', '1567015', '694369', '820054', '1054626', '590393', '754448', '844822', '1432093']\n",
      "after reranking\n",
      "['820054', '694369', '754448', '1432093', '844822', '1054626', '1658569', '1567015', '590393', '1432429']\n",
      "before reranking\n",
      "['829525', '1268725', '823764', '1790201', '1595849', '1452953', '765129', '630056', '1099837', '1251706']\n",
      "after reranking\n",
      "['823764', '1790201', '1452953', '765129', '829525', '1268725', '1099837', '1251706', '630056', '1595849']\n",
      "before reranking\n",
      "['1309138', '846862', '829525', '1218241', '1153609', '715807', '1698916', '810931', '841713', '1595849']\n",
      "after reranking\n",
      "['1218241', '715807', '846862', '1309138', '810931', '829525', '841713', '1153609', '1698916', '1595849']\n",
      "before reranking\n",
      "['740943', '927179', '1088350', '1263783', '585004', '824002', '1410832', '1774106', '1351664', '1611961']\n",
      "after reranking\n",
      "['1774106', '740943', '585004', '1351664', '1263783', '927179', '824002', '1088350', '1410832', '1611961']\n",
      "before reranking\n",
      "['1724137', '1547201', '1547196', '1724304', '1271643', '1516174', '1547210', '1285655', '1529201', '1289174']\n",
      "after reranking\n",
      "['1516174', '1285655', '1724304', '1724137', '1547210', '1289174', '1547196', '1271643', '1529201', '1547201']\n",
      "before reranking\n",
      "['994671', '631788', '533768', '1115313', '1529527', '1728697', '1504378', '749796', '1547019', '1067806']\n",
      "after reranking\n",
      "['1529527', '1547019', '631788', '1504378', '1067806', '1728697', '533768', '994671', '1115313', '749796']\n",
      "before reranking\n",
      "['829525', '1307149', '1246261', '1771987', '1126083', '1595849', '765129', '630056', '1099837', '1387453']\n",
      "after reranking\n",
      "['1307149', '1126083', '765129', '1387453', '829525', '1771987', '1246261', '1099837', '630056', '1595849']\n",
      "before reranking\n",
      "['786163', '1251706', '786235', '585363', '988763', '765054', '1790201', '742549', '1217479', '1251464']\n",
      "after reranking\n",
      "['786163', '742549', '1251464', '1790201', '786235', '765054', '988763', '1217479', '1251706', '585363']\n",
      "before reranking\n",
      "['545003', '721797', '1275665', '1275799', '700241', '1233667', '1602944', '1727208', '750433', '1505510']\n",
      "after reranking\n",
      "['721797', '750433', '1275799', '1275665', '545003', '1233667', '1727208', '1505510', '1602944', '700241']\n",
      "before reranking\n",
      "['1176423', '1350261', '1479089', '730848', '1387726', '745765', '778397', '1133205', '642228', '1404310']\n",
      "after reranking\n",
      "['745765', '1404310', '778397', '1387726', '730848', '1176423', '1133205', '1479089', '1350261', '642228']\n",
      "before reranking\n",
      "['892296', '1113038', '829525', '1234550', '1508979', '1658880', '1595849', '579255', '765129', '630056']\n",
      "after reranking\n",
      "['892296', '1658880', '1508979', '765129', '579255', '1234550', '829525', '630056', '1113038', '1595849']\n",
      "before reranking\n",
      "['1519597', '1168200', '1050889', '818020', '1790201', '742549', '1415335', '1436035', '1251464', '1602852']\n",
      "after reranking\n",
      "['1168200', '742549', '1251464', '1790201', '1519597', '1436035', '1415335', '1050889', '818020', '1602852']\n",
      "before reranking\n",
      "['1567015', '846862', '901098', '703931', '1218241', '1698916', '810931', '1199490', '1790201', '742549']\n",
      "after reranking\n",
      "['1218241', '742549', '703931', '1199490', '1790201', '810931', '846862', '901098', '1567015', '1698916']\n",
      "before reranking\n",
      "['829525', '1234550', '1771987', '1595849', '765129', '630056', '1099837', '1532236', '690121', '1113029']\n",
      "after reranking\n",
      "['765129', '1532236', '1113029', '1234550', '829525', '1771987', '690121', '1099837', '630056', '1595849']\n",
      "before reranking\n",
      "['1547201', '1547196', '1724304', '1724137', '1516174', '1547210', '1285655', '1529201', '1289174', '1289099']\n",
      "after reranking\n",
      "['1285655', '1724304', '1516174', '1289099', '1724137', '1547196', '1289174', '1547210', '1529201', '1547201']\n",
      "before reranking\n",
      "['598370', '691795', '679049', '1017046', '589358', '950412', '1206005', '849900', '1035895', '908521']\n",
      "after reranking\n",
      "['691795', '849900', '598370', '1206005', '1035895', '1017046', '589358', '679049', '950412', '908521']\n",
      "before reranking\n",
      "['967819', '791750', '1059895', '881871', '789811', '767778', '935224', '876985', '828294', '817297']\n",
      "after reranking\n",
      "['828294', '881871', '789811', '1059895', '876985', '817297', '767778', '967819', '791750', '935224']\n",
      "before reranking\n",
      "['796224', '1358525', '682310', '508002', '924898', '1358531', '1522476', '912207', '1523515', '1523147']\n",
      "after reranking\n",
      "['924898', '1522476', '1523147', '682310', '1523515', '796224', '912207', '508002', '1358525', '1358531']\n",
      "before reranking\n",
      "['747929', '659184', '498152', '829525', '616617', '1151345', '492006', '579255', '1595849', '765129']\n",
      "after reranking\n",
      "['492006', '498152', '616617', '765129', '659184', '579255', '829525', '747929', '1151345', '1595849']\n"
     ]
    }
   ],
   "source": [
    "for query in queries_examples:\n",
    "    if retrieved_docs[query]:\n",
    "        print(\"before reranking\")\n",
    "        print(retrieved_docs[query])\n",
    "        print(\"after reranking\")\n",
    "        print(reranked.rerank_lm(retrieved_docs[query], query, lm_documents))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: TypeError: 'NoneType' object is not subscriptable in Python\n",
      "Kendall's Tau: 0.010526315789473684\n",
      "Spearman’s Rank Correlation: 0.019548872180451125\n",
      "\n",
      "Query: NullPointerException handling in Java\n",
      "Kendall's Tau: 0.15789473684210525\n",
      "Spearman’s Rank Correlation: 0.20300751879699244\n",
      "\n",
      "Skipping query 'ModuleNotFoundError: No module named 'requests'': One of the lists is empty\n",
      "Query: Segmentation fault in C++\n",
      "Kendall's Tau: 0.031578947368421054\n",
      "Spearman’s Rank Correlation: 0.009022556390977442\n",
      "\n",
      "Query: SyntaxError: invalid syntax near 'elif'\n",
      "Kendall's Tau: 0.021052631578947368\n",
      "Spearman’s Rank Correlation: 0.12932330827067667\n",
      "\n",
      "Query: Difference between DFS and BFS algorithms\n",
      "Kendall's Tau: 0.052631578947368425\n",
      "Spearman’s Rank Correlation: 0.013533834586466165\n",
      "\n",
      "Query: How does garbage collection work in Java?\n",
      "Kendall's Tau: 0.0736842105263158\n",
      "Spearman’s Rank Correlation: 0.0706766917293233\n",
      "\n",
      "Query: What is tail recursion, and how does it optimize memory\n",
      "Kendall's Tau: 0.5052631578947369\n",
      "Spearman’s Rank Correlation: 0.6451127819548872\n",
      "\n",
      "Query: What are strong and weak references in Python?\n",
      "Kendall's Tau: -0.24210526315789474\n",
      "Spearman’s Rank Correlation: -0.393984962406015\n",
      "\n",
      "Query: Explain dynamic programming with an example\n",
      "Kendall's Tau: 0.15789473684210525\n",
      "Spearman’s Rank Correlation: 0.16541353383458643\n",
      "\n",
      "Query: Best way to concatenate strings in Python\n",
      "Kendall's Tau: -0.1368421052631579\n",
      "Spearman’s Rank Correlation: -0.17293233082706763\n",
      "\n",
      "Query: How to optimize SQL queries for large datasets?\n",
      "Kendall's Tau: 0.08421052631578947\n",
      "Spearman’s Rank Correlation: 0.15939849624060148\n",
      "\n",
      "Query: When to use pointers in C++?\n",
      "Kendall's Tau: 0.23157894736842105\n",
      "Spearman’s Rank Correlation: 0.3398496240601503\n",
      "\n",
      "Query: Why is binary search faster than linear search?\n",
      "Kendall's Tau: -0.10526315789473685\n",
      "Spearman’s Rank Correlation: -0.14285714285714285\n",
      "\n",
      "Query: How to improve performance of nested loops in Java?\n",
      "Kendall's Tau: -0.06315789473684211\n",
      "Spearman’s Rank Correlation: -0.14285714285714285\n",
      "\n",
      "Query: How to use Pandas groupby with multiple columns?\n",
      "Kendall's Tau: -0.08421052631578947\n",
      "Spearman’s Rank Correlation: -0.11428571428571428\n",
      "\n",
      "Query: What does std::move do in C++?\n",
      "Kendall's Tau: -0.4210526315789474\n",
      "Spearman’s Rank Correlation: -0.5308270676691729\n",
      "\n",
      "Query: Difference between apply() and map() in Pandas\n",
      "Kendall's Tau: -0.06315789473684211\n",
      "Spearman’s Rank Correlation: -0.08421052631578946\n",
      "\n",
      "Query: How to use React hooks for state management?\n",
      "Kendall's Tau: 0.0\n",
      "Spearman’s Rank Correlation: -0.003007518796992481\n",
      "\n",
      "Query: How to make an API request with Axios in JavaScript?\n",
      "Kendall's Tau: -0.1473684210526316\n",
      "Spearman’s Rank Correlation: -0.19849624060150375\n",
      "\n",
      "Query: I want pasta for dinner\n",
      "Kendall's Tau: 0.10526315789473685\n",
      "Spearman’s Rank Correlation: 0.23609022556390977\n",
      "\n",
      "Query: coding is very hard\n",
      "Kendall's Tau: 0.0736842105263158\n",
      "Spearman’s Rank Correlation: 0.08721804511278194\n",
      "\n",
      "Query: ajdejfn code\n",
      "Kendall's Tau: 0.22105263157894736\n",
      "Spearman’s Rank Correlation: 0.34736842105263155\n",
      "\n",
      "Query: how to make a website\n",
      "Kendall's Tau: 0.052631578947368425\n",
      "Spearman’s Rank Correlation: 0.0781954887218045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def calculate_rank_correlation(retrieved_docs, reranked_doc_list):\n",
    "    \"\"\"\n",
    "    Calculates Kendall's Tau and Spearman's Rank Correlation\n",
    "    between the retrieved and re-ranked document lists.\n",
    "    \"\"\"\n",
    "    correlation_results = {}\n",
    "\n",
    "    for query in reranked_doc_list:\n",
    "        retrieved_list = retrieved_docs[query]\n",
    "        reranked_list = reranked_doc_list[query]\n",
    "\n",
    "        # ensure for empty\n",
    "        if not retrieved_list or not reranked_list:\n",
    "            print(f\"Skipping query '{query}': One of the lists is empty\")\n",
    "            continue\n",
    "\n",
    "        # Compute Kendall's Tau and Spearman's Rank Correlation\n",
    "        kendall_tau_ = kendalltau(retrieved_list, reranked_list).correlation\n",
    "        spearman_corr_ = spearmanr(retrieved_list, reranked_list).correlation\n",
    "\n",
    "        correlation_results[query] = {\n",
    "            \"Kendall's Tau\": kendall_tau_,\n",
    "            \"Spearman's Rank Correlation\": spearman_corr_\n",
    "        }\n",
    "\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Kendall's Tau: {kendall_tau_}\")\n",
    "        print(f\"Spearman’s Rank Correlation: {spearman_corr_}\\n\")\n",
    "\n",
    "    return correlation_results\n",
    "\n",
    "correlation_results = calculate_rank_correlation(retrieved_docs, reranked_doc_list)\n",
    "\n",
    "#If τ is low but re-ranking makes sense based on metadata/LM, it may be good.\n",
    "#If τ is high, re-ranking didn’t change much.\n",
    "\n",
    "#small value for all of them\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
