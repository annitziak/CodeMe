{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing notebook\n",
    "# test for query processing time\n",
    "# test for different results when different methods are used.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# use abs path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from retrieval_models.data_loaders import Index\n",
    "from retrieval_models.retrieval_functions import *\n",
    "from retrieval_models.reranking import Reranker\n",
    "from retrieval_models.evaluation_metrics import *\n",
    "import tqdm \n",
    "import os\n",
    "import time\n",
    "from scipy.stats import kendalltau, spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'NoneType' object is not subscriptable in Python\n"
     ]
    }
   ],
   "source": [
    "#import all the examples\n",
    "queries_examples = []\n",
    "BASE_DIR = os.getcwd()\n",
    "index_path = os.path.join(BASE_DIR, \"data\", \"queries_examples.txt\")\n",
    "with open(index_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "    queries_examples = [line.strip() for line in file if line.strip()]  # Remove empty lines\n",
    "\n",
    "print(queries_examples[0]) #print the first one for example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1127363:\n",
      "Skipping invalid doc_info line: \t1127363:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t1127363:\n",
      "Skipping invalid doc_info line: \t1449406:\n",
      "Skipping invalid doc_info line: \t820167:\n",
      "Skipping invalid doc_info line: \t820167:\n",
      "done loading index positions\n",
      "done finding vocab\n",
      "c:\\Users\\annie\\ttds_assignment\\retrieval_models\\data\\doc_metadata.txt\n",
      "done loading doc lengths\n"
     ]
    }
   ],
   "source": [
    "#initialize the object index \n",
    "# ignore the errors is because of the preprocessing done at this stage and it ignores some terms\n",
    "index = Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['httpservletrequestwrapper', 'httpservletrequestwrapp', \"httpservletrequest'\", 'httpservletrequest', 'httpservletrequ', 'httpservletreqest', 'httpservletresponsewrapper', 'httpservletresponsewrapp', \"httpservletresponse'\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 9995/9995 [5:05:03<00:00,  1.83s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings successfully saved to retrieval_models/data/vocab_embeddings.pkl\n",
      "🔍 File confirmed at retrieval_models/data/vocab_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "# precompute the embeddings\n",
    "# no need to run this again \n",
    "#print(index.vocab[1:10])\n",
    "#embeddingmodel = EmbeddingModel(vocab = index.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: [-0.17391707  0.34074134  0.0786799  -0.01539922  0.08461355] of size 768...\n"
     ]
    }
   ],
   "source": [
    "def load_and_get_embedding(word, save_path=\"retrieval_models/data/vocab_embeddings.pkl\"):\n",
    "    with open(save_path, \"rb\") as f:\n",
    "        embeddings, word_to_index = pickle.load(f)\n",
    "    \n",
    "    return embeddings[word_to_index[word]] if word in word_to_index else None\n",
    "\n",
    "# Example usage\n",
    "embedding_vector = load_and_get_embedding(\"java\")\n",
    "if embedding_vector is not None:\n",
    "    print(f\"Embedding: {embedding_vector[:5]} of size {len(embedding_vector)}...\")  # Print first 5 values for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over queries and print results\n",
    "def run_queries(queries_examples, index, embedding_model=None, expansion=False, k=10):\n",
    "    \"\"\"\n",
    "    Runs retrieval for a list of queries and prints top results.\n",
    "    Also prints the total execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    retrieved_docs = {}\n",
    "    \n",
    "    for query in tqdm.tqdm(queries_examples):\n",
    "        print(\"Query:\", query)\n",
    "        top_results = retrieval_function(query, index,embedding_model, expansion, k)\n",
    "        print(\"Top results:\", top_results)\n",
    "        print(\"\\n\")\n",
    "        retrieved_docs[query]=top_results\n",
    "\n",
    "    end_time = time.time()  # End timer\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    print(f\"Total Execution Time: {total_time:.4f} seconds\")\n",
    "    print(f\"Average Time per Query: {total_time / len(queries_examples):.4f} seconds\")\n",
    "\n",
    "    return retrieved_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: TypeError: 'NoneType' object is not subscriptable in Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:00<00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1408286', '1521909', '1612220', '1261875', '1274875', '1061361', '788982', '1713444', '707812', '635716']\n",
      "\n",
      "\n",
      "Query: NullPointerException handling in Java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:01<00:11,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1247154', '1024206', '862483', '661131', '1223415', '1076494', '1218729', '1775881', '992937', '1040269']\n",
      "\n",
      "\n",
      "Query: ModuleNotFoundError: No module named 'requests'\n",
      "Top results: ['673174', '1305042', '1003843', '1070269', '1389141', '1621999', '1350574', '1518779', '1228613', '953786']\n",
      "\n",
      "\n",
      "Query: Segmentation fault in C++\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:01<00:05,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['671703', '1771485', '1691014', '1770481', '925890', '1340181', '1114874', '1763334', '1637560', '1101971']\n",
      "\n",
      "\n",
      "Query: SyntaxError: invalid syntax near 'elif'\n",
      "Top results: ['1452239', '971177', '829798', '584284', '1227605', '1732030', '1102673', '1388072', '1390400', '1281654']\n",
      "\n",
      "\n",
      "Query: Difference between DFS and BFS algorithms\n",
      "Top results: ['1658569', '1547167', '1292367', '1432429', '1078385', '1612334', '931746', '1054626', '645171', '854559']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [00:01<00:03,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does garbage collection work in Java?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:02<00:04,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['858650', '1584024', '700993', '785934', '632410', '1382563', '1318665', '1224205', '709375', '947053']\n",
      "\n",
      "\n",
      "Query: What is tail recursion, and how does it optimize memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:02<00:04,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['747408', '1009860', '947681', '851445', '806536', '1712953', '716360', '1626915', '518365', '1708104']\n",
      "\n",
      "\n",
      "Query: What are strong and weak references in Python?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [00:02<00:03,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1208194', '539446', '1454803', '1189322', '1434379', '1080190', '1418536', '1360989', '1208153', '740969']\n",
      "\n",
      "\n",
      "Query: Explain dynamic programming with an example\n",
      "Top results: ['663431', '1283286', '1408828', '1712579', '1540882', '1490130', '1728181', '882687', '1521988', '1498163']\n",
      "\n",
      "\n",
      "Query: Best way to concatenate strings in Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:03<00:03,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['665499', '845003', '1353943', '550750', '635716', '670168', '1468197', '1467300', '1184661', '1208267']\n",
      "\n",
      "\n",
      "Query: How to optimize SQL queries for large datasets?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [00:03<00:03,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1327950', '613283', '1478296', '584866', '647149', '1276306', '553934', '1173799', '1086270', '1171180']\n",
      "\n",
      "\n",
      "Query: When to use pointers in C++?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [00:04<00:03,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['892186', '1563574', '682812', '891125', '1152961', '640613', '716360', '1399785', '842829', '1212175']\n",
      "\n",
      "\n",
      "Query: Why is binary search faster than linear search?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [00:04<00:03,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['545003', '894642', '896742', '1511551', '1152185', '780031', '1527161', '1143488', '1109544', '1168899']\n",
      "\n",
      "\n",
      "Query: How to improve performance of nested loops in Java?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [00:04<00:02,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['858650', '1694602', '1151806', '1420956', '1327950', '1564869', '1287762', '1334467', '761204', '1104444']\n",
      "\n",
      "\n",
      "Query: How to use Pandas groupby with multiple columns?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [00:04<00:02,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1319371', '1599211', '1138994', '1413855', '1208947', '1721585', '1345987', '1161312', '1403620', '1459871']\n",
      "\n",
      "\n",
      "Query: What does std::move do in C++?\n",
      "Top results: ['604651', '1239927', '1608174', '449445', '851445', '512605', '1009860', '1762111', '688687', '1445069']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:05<00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Difference between apply() and map() in Pandas\n",
      "Top results:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:05<00:01,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ['1078385', '1461027', '854559', '889616', '1547167', '539446', '861115', '1292367', '1025513', '1612334']\n",
      "\n",
      "\n",
      "Query: How to use React hooks for state management?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [00:05<00:01,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1346793', '1526324', '1345987', '571408', '1176054', '665922', '889636', '772719', '1023320', '1050795']\n",
      "\n",
      "\n",
      "Query: How to make an API request with Axios in JavaScript?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [00:06<00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1420956', '1244217', '1774603', '1341103', '549311', '1137552', '1311148', '1395062', '1661670', '734755']\n",
      "\n",
      "\n",
      "Query: I want pasta for dinner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [00:06<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1084009', '1662827', '598370', '1017046', '1103573', '1621294', '959620', '679049', '825677', '1104106']\n",
      "\n",
      "\n",
      "Query: coding is very hard\n",
      "Top results: ['1430292', '492284', '1104789', '492262', '1170558', '1135854', '605357', '703088', '1006463', '890929']\n",
      "\n",
      "\n",
      "Query: ajdejfn code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [00:07<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['682310', '807267', '642516', '498457', '648299', '1020721', '875521', '1102436', '1088479', '1141338']\n",
      "\n",
      "\n",
      "Query: how to make a website\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:07<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results: ['1194880', '1512080', '1244021', '1187004', '1422187', '718924', '1337743', '1205927', '1566748', '1334971']\n",
      "\n",
      "\n",
      "Total Execution Time: 7.8640 seconds\n",
      "Average Time per Query: 0.3277 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#the basic top 10 results for each query\n",
    "retrieved_docs = run_queries(queries_examples, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from retrieval_models/data/vocab_embeddings.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: TypeError: 'NoneType' object is not subscriptable in Python\n",
      "Word 'typeerror:' not found in precomputed embeddings. Computing on the fly?...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m embeddingmodel \u001b[38;5;241m=\u001b[39m EmbeddingModel(vocab \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[1;32m----> 2\u001b[0m retrieved_docs_expansion \u001b[38;5;241m=\u001b[39m run_queries(queries_examples, index, embeddingmodel, expansion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m, in \u001b[0;36mrun_queries\u001b[1;34m(queries_examples, index, embedding_model, expansion, k)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(queries_examples):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery:\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)\n\u001b[1;32m---> 13\u001b[0m     top_results \u001b[38;5;241m=\u001b[39m retrieval_function(query, index,embedding_model, expansion, k)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop results:\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_results)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\annie\\ttds_assignment\\retrieval_models\\retrieval_functions.py:67\u001b[0m, in \u001b[0;36mretrieval_function\u001b[1;34m(query, index, embedding_model, expansion, k)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Apply query expansion if requested\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expansion \u001b[38;5;129;01mand\u001b[39;00m embedding_model:\n\u001b[1;32m---> 67\u001b[0m     tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m query_expansion(tokens, embedding_model)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Score aggregation for BM25 retrieval\u001b[39;00m\n\u001b[0;32m     70\u001b[0m aggregated_scores \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\annie\\ttds_assignment\\retrieval_models\\retrieval_functions.py:18\u001b[0m, in \u001b[0;36mquery_expansion\u001b[1;34m(preprocessed_query, embedding_model, top_k)\u001b[0m\n\u001b[0;32m     16\u001b[0m extra_terms \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m preprocessed_query:\n\u001b[1;32m---> 18\u001b[0m     extra_terms\u001b[38;5;241m.\u001b[39mappend(embedding_model\u001b[38;5;241m.\u001b[39mfind_similar_words(word, top_k))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(extra_terms))\n",
      "File \u001b[1;32mc:\\Users\\annie\\ttds_assignment\\retrieval_models\\query_expansion.py:118\u001b[0m, in \u001b[0;36mEmbeddingModel.find_similar_words\u001b[1;34m(self, word, top_k)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03mFinds the top_k most similar words to the given word using cosine similarity.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    list: A list of words most similar to the input word.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m target_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_embedding(word)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure correct shape\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(target_embedding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    119\u001b[0m top_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:top_k]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_indices]\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1583\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1581\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n\u001b[0;32m   1582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1583\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1585\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[0;32m   1587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1843\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# axis == 1:\u001b[39;00m\n\u001b[0;32m   1841\u001b[0m     sparse_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1843\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1844\u001b[0m     X,\n\u001b[0;32m   1845\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39msparse_format,\n\u001b[0;32m   1846\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1847\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe normalize function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1849\u001b[0m )\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1851\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:988\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 988\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    989\u001b[0m             array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    990\u001b[0m         )\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[0;32m    993\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    994\u001b[0m         array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    995\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\annie\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:378\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddingmodel = EmbeddingModel(vocab = index.vocab)\n",
    "retrieved_docs_expansion = run_queries(queries_examples, index, embeddingmodel, expansion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_clarity_score(retrieved_docs, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1408286', '1521909', '1612220', '1261875', '1274875', '1061361', '788982', '1713444', '707812', '635716']\n",
      "after reranking\n",
      "['1261875', '788982', '635716', '707812', '1274875', '1061361', '1408286', '1612220', '1521909', '1713444']\n",
      "['1247154', '1024206', '862483', '661131', '1223415', '1076494', '1218729', '1775881', '992937', '1040269']\n",
      "after reranking\n",
      "['1024206', '1247154', '1076494', '661131', '1223415', '1218729', '992937', '1040269', '862483', '1775881']\n",
      "['673174', '1305042', '1003843', '1070269', '1389141', '1621999', '1350574', '1518779', '1228613', '953786']\n",
      "after reranking\n",
      "['673174', '1389141', '1350574', '953786', '1003843', '1305042', '1070269', '1228613', '1621999', '1518779']\n",
      "['671703', '1771485', '1691014', '1770481', '925890', '1340181', '1114874', '1763334', '1637560', '1101971']\n",
      "after reranking\n",
      "['1771485', '671703', '1114874', '1101971', '1340181', '925890', '1763334', '1770481', '1691014', '1637560']\n",
      "['1452239', '971177', '829798', '584284', '1227605', '1732030', '1102673', '1388072', '1390400', '1281654']\n",
      "after reranking\n",
      "['584284', '1227605', '971177', '1388072', '829798', '1102673', '1732030', '1452239', '1390400', '1281654']\n",
      "['1658569', '1547167', '1292367', '1432429', '1078385', '1612334', '931746', '1054626', '645171', '854559']\n",
      "after reranking\n",
      "['1612334', '854559', '1054626', '931746', '645171', '1078385', '1292367', '1432429', '1547167', '1658569']\n",
      "['858650', '1584024', '700993', '785934', '632410', '1382563', '1318665', '1224205', '709375', '947053']\n",
      "after reranking\n",
      "['632410', '858650', '785934', '947053', '709375', '700993', '1318665', '1382563', '1224205', '1584024']\n",
      "['747408', '1009860', '947681', '851445', '806536', '1712953', '716360', '1626915', '518365', '1708104']\n",
      "after reranking\n",
      "['1009860', '518365', '716360', '947681', '806536', '747408', '851445', '1626915', '1708104', '1712953']\n",
      "['1208194', '539446', '1454803', '1189322', '1434379', '1080190', '1418536', '1360989', '1208153', '740969']\n",
      "after reranking\n",
      "['740969', '1208153', '539446', '1360989', '1080190', '1418536', '1208194', '1454803', '1189322', '1434379']\n",
      "['663431', '1283286', '1408828', '1712579', '1540882', '1490130', '1728181', '882687', '1521988', '1498163']\n",
      "after reranking\n",
      "['663431', '1540882', '882687', '1728181', '1283286', '1408828', '1498163', '1490130', '1712579', '1521988']\n",
      "['665499', '845003', '1353943', '550750', '635716', '670168', '1468197', '1467300', '1184661', '1208267']\n",
      "after reranking\n",
      "['635716', '665499', '845003', '670168', '550750', '1208267', '1467300', '1353943', '1184661', '1468197']\n",
      "['1327950', '613283', '1478296', '584866', '647149', '1276306', '553934', '1173799', '1086270', '1171180']\n",
      "after reranking\n",
      "['553934', '584866', '647149', '1086270', '613283', '1173799', '1327950', '1171180', '1276306', '1478296']\n",
      "['892186', '1563574', '682812', '891125', '1152961', '640613', '716360', '1399785', '842829', '1212175']\n",
      "after reranking\n",
      "['640613', '716360', '892186', '842829', '682812', '891125', '1152961', '1212175', '1399785', '1563574']\n",
      "['545003', '894642', '896742', '1511551', '1152185', '780031', '1527161', '1143488', '1109544', '1168899']\n",
      "after reranking\n",
      "['1143488', '896742', '1109544', '1152185', '780031', '545003', '1527161', '894642', '1168899', '1511551']\n",
      "['858650', '1694602', '1151806', '1420956', '1327950', '1564869', '1287762', '1334467', '761204', '1104444']\n",
      "after reranking\n",
      "['761204', '858650', '1420956', '1151806', '1287762', '1104444', '1327950', '1334467', '1564869', '1694602']\n",
      "['1319371', '1599211', '1138994', '1413855', '1208947', '1721585', '1345987', '1161312', '1403620', '1459871']\n",
      "after reranking\n",
      "['1319371', '1161312', '1138994', '1208947', '1345987', '1721585', '1459871', '1413855', '1403620', '1599211']\n",
      "['604651', '1239927', '1608174', '449445', '851445', '512605', '1009860', '1762111', '688687', '1445069']\n",
      "after reranking\n",
      "['1009860', '449445', '688687', '1608174', '512605', '604651', '851445', '1239927', '1445069', '1762111']\n",
      "['1078385', '1461027', '854559', '889616', '1547167', '539446', '861115', '1292367', '1025513', '1612334']\n",
      "after reranking\n",
      "['1612334', '861115', '854559', '889616', '539446', '1025513', '1078385', '1292367', '1461027', '1547167']\n",
      "['1346793', '1526324', '1345987', '571408', '1176054', '665922', '889636', '772719', '1023320', '1050795']\n",
      "after reranking\n",
      "['772719', '665922', '571408', '889636', '1526324', '1050795', '1023320', '1346793', '1345987', '1176054']\n",
      "['1420956', '1244217', '1774603', '1341103', '549311', '1137552', '1311148', '1395062', '1661670', '734755']\n",
      "after reranking\n",
      "['549311', '1420956', '1341103', '734755', '1661670', '1244217', '1774603', '1137552', '1395062', '1311148']\n",
      "['1084009', '1662827', '598370', '1017046', '1103573', '1621294', '959620', '679049', '825677', '1104106']\n",
      "after reranking\n",
      "['679049', '1017046', '598370', '1104106', '1103573', '1084009', '825677', '959620', '1621294', '1662827']\n",
      "['1430292', '492284', '1104789', '492262', '1170558', '1135854', '605357', '703088', '1006463', '890929']\n",
      "after reranking\n",
      "['492262', '1104789', '703088', '492284', '1006463', '1135854', '605357', '1430292', '890929', '1170558']\n",
      "['682310', '807267', '642516', '498457', '648299', '1020721', '875521', '1102436', '1088479', '1141338']\n",
      "after reranking\n",
      "['682310', '648299', '498457', '1020721', '807267', '1141338', '642516', '875521', '1088479', '1102436']\n",
      "['1194880', '1512080', '1244021', '1187004', '1422187', '718924', '1337743', '1205927', '1566748', '1334971']\n",
      "after reranking\n",
      "['1187004', '1337743', '1422187', '718924', '1566748', '1194880', '1244021', '1205927', '1334971', '1512080']\n"
     ]
    }
   ],
   "source": [
    "#testing to see whether the reranker returns them in different order\n",
    "\n",
    "reranked = Reranker()\n",
    "#print(reranked.metadata)\n",
    "reranked.metadata[\"id\"] = reranked.metadata[\"id\"].astype(str).str.strip()\n",
    "reranked.metadata.fillna(0,inplace=True)\n",
    "reranked_doc_list={}\n",
    "for key,retrieved_docs_list in retrieved_docs.items():\n",
    "    print(retrieved_docs_list)\n",
    "    print(\"after reranking\")\n",
    "    reranked_doc_list[key]=reranked.rerank(retrieved_docs_list)\n",
    "    print(reranked_doc_list[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tau value for re ranked documents\n",
      "Kendall's Tau: SignificanceResult(statistic=0.022222222222222223, pvalue=1.0)\n",
      "Spearman’ s Rank Correlation: SignificanceResult(statistic=0.17575757575757575, pvalue=0.6271883447764844)\n"
     ]
    }
   ],
   "source": [
    "for key in reranked_doc_list.items():\n",
    "\n",
    "    kendall_tau_ = kendalltau(retrieved_docs[key], reranked_doc_list[key])\n",
    "    spearman_corr_ = spearmanr(retrieved_docs[key], reranked_doc_list[key])\n",
    "    print('the tau value for re ranked documents')\n",
    "    print(f\"Kendall's Tau: {kendall_tau_}\")\n",
    "    print(f\"Spearman’ s Rank Correlation: {spearman_corr_}\")\n",
    "\n",
    "#If τ is low but re-ranking makes sense based on metadata/LM, it may be good.\n",
    "#If τ is high, re-ranking didn’t change much.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
